Ниже приведён детальный разбор вашего «Problem Statement» с учётом реальной реализации в коде. Постараюсь сохранить вашу форму́лировку и стиль, исправляя лишь неточности и добавляя необходимые пояснения и логические переходы.

---

## 1. Исходный текст и общие замечания

> **Оригинал (с небольшими правками для читабельности):**
> \section{NEW: Problem Statement}
>
> Ставится задача классификации на датасете \$\mathfrak D={(x\_i,y\_i)}\_{i=1}^{\mathcal N}\$, значения --- \$x\_i\in\mathbf X\$, таргеты --- \$y\_i\in\mathbf Y\$.
> Предлагаемый метод опирается на классический DARTS: нейросеть представляется как последовательность повторяющихся частей --- **клеток**. Каждая клетка имеет одинаковую структуру, но различные параметры внутри. Её можно представить как ориентированный ациклический граф с вершинами \$V = {1,\dots,N}\$ и рёбрами
>
> $$
>     E = \{\, (i,j)\in V\times V\mid i<j\,\}.
> $$
>
> Для каждого ребра назначена операция \$\mathbf{g}\$, а все операции между двумя вершинами объединены в вектор \$\vec{\mathbf{g}}\$. Значение в каждой вершине представляется через входящие вектора и предыдущие вершины:
>
> $$
>     \boldsymbol{x}^{(j)} = \sum_{\substack{(i,j)\in E\\ i<j}} \mathbf{g}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr).
> $$
>
> Задача поиска оптимальной архитектуры заключается в выборе операции \$\mathbf{g}\$ для каждого ребра в каждой клетке и получении при этой структуре лучшей метрики качества на задаче.
>
> \subsection{Гиперсеть для контроля сложности}
>
> Для обучения используется сведение дискретной задачи оптимизации к непрерывной при помощи «смешанной» (mixed) операции \cite{yakovlev2021neural}, \cite{}:
>
> $$
>     \hat{\mathbf{g}}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr) 
>     = \langle\,\gamma^{(i,j)},\,\vec{\mathbf{g}}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr)\rangle, 
>     \quad 
>     \gamma^{(i,j)} \sim \mathrm{GS}\bigl(\exp(\alpha^{(i,j)}),\,t\bigr),
> $$
>
> где \$\alpha^{(i,j)}\$ — структурные параметры, определяющие влияние каждой операции в \$\vec{\mathbf{g}}^{(i,j)}\$, \$t\$ — температура для распределения Гумбеля–Софтмакс, \$\gamma^{(i,j)}\$ — итоговые «веса» операций для ребра \$(i,j)\$.
>
> Вместо обучения фиксированных структурных параметров \$\alpha^{(i,j)}\$, предлагается генерировать их через **гиперсеть**. Для этого вводится вектор сложности
>
> $$
> \mathbf S\in\Delta^{k-1} \;=\; \Bigl\{\mathbf S\in\mathbb R^{k}\,\Bigm|\,\sum_{j=1}^k S_j=1,\; S_j\ge0\Bigr\},
> $$
>
> который сэмплируется один раз за mini‐batch из равномерного распределения по симплексу.
> Теперь \$\alpha: \Delta^{k-1}\times \mathbb R^{d\_a}\to \mathbb R^m\$ — гиперсеть с параметрами \$\boldsymbol a\$, сопоставляющая вектор сложности параметрам структурных весов клетки.
>
> \subsection{Оптимизационная задача}
>
> Каждая «примитивная» операция \$g^{(m)}\$ ассоциирована с измеренной латентностью \$L^{(m)}\$ на целевой аппаратуре; латентность собранной архитектуры \$\boldsymbol\gamma\$ вычисляется как
>
> $$
> \mathrm{Latency}(\boldsymbol\gamma)
> \;=\;
> \sum_{(i,j)\in E} \sum_{m=1}^{k} \gamma^{(m)}_{(i,j)}\,L^{(m)}.
> $$
>
> Мы обучаем параметы сети \$\boldsymbol w\$ и параметры гиперсети \$\boldsymbol a\$, минимизируя **одноуровневую** функцию потерь:
>
> $$
> \min_{\boldsymbol w,\boldsymbol a}\;
> \mathbb E_{\mathbf S\sim\mathcal U(\Delta^{k-1})}\;
> \mathbb E_{\boldsymbol\gamma\sim\mathrm{GS}\bigl(H_{\boldsymbol a}(\mathbf S),\,t\bigr)} 
> \Bigl[\,
> \underbrace{\mathcal L_{\mathrm{task}}(\boldsymbol w,\boldsymbol\gamma)}_{\text{кросс‐энтропия на данных}}
> \;+\;
> \kappa\,\mathrm{Latency}(\boldsymbol\gamma)
> \Bigr],
> $$
>
> где \$\kappa>0\$ задаёт баланс «точность—латентность».

В целом идея сформулирована верно, но в тексте не хватает уточнений, где именно соответствуют переменные из кода, а также некоторых логических связок. Ниже приведу пошаговые комментарии, укажу (в скобках) на то, как это выглядит в вашем коде, и предложу чуть более развёрнутый вариант на русском с минимальными изменениями.

---

## 2. Детальный разбор и комментарии

### 2.1. Общая постановка задачи

1. Вы пишете:

   > Ставится задача классификации на датасете \$\mathfrak D={(x\_i,y\_i)}\_{i=1}^{\mathcal N}\$, значения — \$x\_i\in\mathbf X\$, таргеты — \$y\_i\in\mathbf Y\$.

   **Комментарий.** Тут всё корректно. Можно уточнить, что \$\mathcal N\$ — число примеров в обучающей выборке, \$\mathbf X\$ — пространство признаков (например, изображения), \$\mathbf Y\$ — множество меток.

2. Далее:

   > Метод опирается на DARTS: сеть представляется как последовательность **клеток**, каждая клетка — ориентированный ациклический граф с вершинами \$V={1,\dots,N}\$ и рёбрами \$E={(i,j)\mid i\<j}\$.

   **Комментарий.**

   * В коде (файл `models/cnn/search_cells.py`) у вас по умолчанию \$N=4\$ (количество внутренних узлов) плюс два «фиксированных» входа.
   * Можно добавить: «При этом обычно в реализации DARTS каждая клетка имеет 2 «фиковых» входа (результаты двух предыдущих слоёв) и \$N\$ промежуточных узлов». Но если вы хотите не углубляться, достаточно сказать «\$N\$ вспомогательных узлов».

3. Далее формула

$$

\boldsymbol{x}^{(j)} = \sum\_{(i,j)\in E} \mathbf{g}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr).

$$

**Комментарий.** Точнее:  
 Объединение через сумму по всем входящим рёбрам $(i,j)\in E$.  

В коде (`SearchCell`) вы действительно делаете итерацию по `dag` и суммируете выходы `mixed_op(x_i)`.  

4. Вы пишете:  
 Задача поиска архитектуры — выбрать $\mathbf{g}$ на каждом ребре так, чтобы снизить ошибку на задаче.  

**Комментарий.** Тут можно добавить, что в классическом DARTS каждая $\mathbf{g}^{(i,j)}$ является «смешанной новперацией» (mixed operation):  
$$

\widehat{\mathbf{g}}^{(i,j)}(x)
\= \sum\_{m=1}^k \alpha^{(i,j)}\_m,\mathbf{o}^{(m)}(x),

$$
где $\{\mathbf{o}^{(m)}\}_{m=1}^k$ — базовые (primitive) операции. В вашем же методе вместо фиксированных $\alpha^{(i,j)}$ в каждой клетке вы генерируете их через гиперсеть, зависимую от «вектора сложности» $\mathbf S$.  

---

### 2.2. «Смешанная» операция и Gumbel‐Softmax

5. Ваш текст:
> Для обучения сводим дискретную задачу к непрерывной при помощи mixed‐операции:
> $$
> \hat{\mathbf{g}}^{(i,j)}(\boldsymbol{x}^{(i)}) 
> = \langle \gamma^{(i,j)}, \vec{\mathbf{g}}^{(i,j)}(\boldsymbol{x}^{(i)}) \rangle, 
> \quad 
> \gamma^{(i,j)} \sim GS\bigl(\exp(\alpha^{(i,j)}),\,t\bigr),
> $$
> где $\alpha^{(i,j)}$ — структурные параметры, $t$ — температура, $\gamma^{(i,j)}$ — итоговые параметры операций.  

**Замечания и уточнения:**
1. **Что такое $\vec{\mathbf{g}}^{(i,j)}(\cdot)$?**  
   В тексте вы написали «все операции между двумя вершинами объединены в вектор $\vec{\mathbf{g}}$». Если кратко:  
   $$
   \vec{\mathbf{g}}^{(i,j)}(\boldsymbol{x}^{(i)}) 
   = \bigl[\mathbf{o}_1(\boldsymbol{x}^{(i)}),\;\mathbf{o}_2(\boldsymbol{x}^{(i)}),\;\dots,\;\mathbf{o}_k(\boldsymbol{x}^{(i)})\bigr],
   $$
   где $\{\mathbf{o}_m\}_{m=1}^k$ — набор «примитивных» операций (conv3×3, conv5×5, max‐pooling, skip‐connect, «none» и т.д.). В коде эти операции лежат в списке `primitives`, а за создание «смешанной» операции отвечает класс `MixedOp` (в `models/cnn/ops.py`).  

2. **Почему $\gamma\sim GS(\exp(\alpha), t)$?**  
   В оригинальном DARTS «софт‐макс» обходится простым $ \mathrm{Softmax}(\alpha)$, но когда вы хотите семплировать одно‐горячие вектора с «гумбелевой» техникой, используете *Gumbel‐Softmax* (RelaxedOneHotCategorical). В коде (`SearchCNNControllerWithHyperNet.forward`) при `sampling_mode='gumbel-softmax'` вы вызываете  
   ```python
   torch.distributions.RelaxedOneHotCategorical(self.t, logits=alpha(lam)).rsample([batch_size])
   ```
   То есть вы семплируете $\gamma$ размером `[batch_size, k]` непосредственно внутри батча.  
   
   При `sampling_mode='softmax'` вы просто берёте
   ```python
   F.softmax(alpha(lam)/self.t, dim=-1)
   ```
   То есть детерминированно берёте «плавные» веса операций.  

3. **Обозначения.**  
   - $\alpha^{(i,j)}$ — логиты, которые даёт гиперсеть (конкретно: в коде это объект `alpha(lam)`, где `alpha` — экземпляр класса `HyperNet`).  
   - Затем, в зависимости от режима, вы либо берёте $q = \mathrm{Softmax}(\alpha/t)$, либо семплируете $q\sim\mathrm{GumbelSoftmax}(\alpha, t)$. Получив $q$, вы передаёте его в `MixedOp`: он считает  
     $$
       \widehat{\mathbf{g}}^{(i,j)}(x) 
       = \sum_{m=1}^k q_m\,\mathbf{o}_m(x).
     $$
   - В вашем тексте фигурирует нотация $\langle \gamma, \vec{\mathbf{g}}\rangle$, где $\gamma = (\gamma_1,\dots,\gamma_k)$, а $\vec{\mathbf{g}}(x) = (\mathbf{o}_1(x),\dots,\mathbf{o}_k(x))$.  

6. **Важно уточнить: в коде во время *обучения структуры* (функция `hyperloss`) вы НЕ используете Gumbel‐Softmax, а всегда берёте detеrministic Softmax**:  
```python
weights = [alpha(lam) for alpha in self.hyper_normal]   # сырые логиты
weights = [F.softmax(w, dim=-1) for w in weights]       # детерминированный Softmax
```
То есть даже если `sampling_mode == 'gumbel-softmax'`, метод `hyperloss` внутри берет детерминированные «плавные» веса $q = \mathrm{Softmax}(\alpha)$ (без шума). Гумбелевый режим в коде используется только в прямом проходе `forward` при ездеем батчей и, видимо, при финальном семплировании архитектур на валидации/тесте.  

Следовательно, **в тексте нужно отметить**, что внутри «гипер‐потерь» мы всегда используем $\gamma = \mathrm{Softmax}(\alpha)$ (без Gumbel‐шума). В более общем виде можно написать:  
$$

\gamma^{(i,j)} =
\begin{cases}
\mathrm{GumbelSoftmax}\bigl(\alpha^{(i,j)}(\mathbf S),,t\bigr),
&\text{если мы семплируем архитектуру при прямом проходе;}\\
\mathrm{Softmax}\bigl(\alpha^{(i,j)}(\mathbf S)\bigr),
&\text{если мы считаем «гипер‐потери» для обновления параметров.}
\end{cases}

$$

---

### 2.3. Гиперсеть (HyperNet) — генерация $\alpha$ через $S$

7. **Ваш текст:**
> Вместо обучения структурных параметров $\alpha$, предлагается генерировать их через гиперсеть. Для этого вводится вектор сложности  
> $$
> \mathbf S\in\Delta^{k-1} = \bigl\{\mathbf S\in\mathbb R^{k}\,\bigl|\,\sum_{j=1}^kS_j=1,\,S_j\ge0\bigr\},
> $$
> который сэмплируется один раз за mini‐batch из равномерного распределения над симплексом.  
> Теперь $\alpha: \Delta^{k-1}\times a\to \gamma$ — гиперсеть с параметрами $\boldsymbol a$, сопоставляющая вектор сложности — параметрам архитектуры клетки.  

**Комментарий.**  
- В коде класс, создающий гиперсеть, называется либо `HyperNet` (см. `models/cnn_darts_hypernet/architect.py`), либо частично упрощённый `Hypernet2`/`HyperLinear` (небольшая собственная надстройка, похоже, для финального линейного слоя).  
- Главное: гиперсеть принимает на вход параметр лямбда (обозначим его $S$ или $\lambda$ — в тексте и в коде вы смешиваете нотации “$S$” и “$\lambda$” для вектора сложности), а на выходе выдаёт логиты $\alpha^{(i,j)}$. В частности, если в коде `lambda` обозначена как `lam` и это тензор размера `[batch_size, k]`, то для каждой ячейки (node) у вас есть свой экземпляр `HyperNet`, который вычисляет `alpha(lam)`, результатом чего является тензор `[batch_size, number_of_ops]`.  
- Важно в тексте **разделить** понятие:  
  1. **$\mathbf S$** или **$\lambda$** — вектор сложности, который *сэмплируется* из стандартного симплекса (в коде: `k = Exponential(1).sample([SIMPLEX_D]); lam = k / sum(k)`).  
  2. **$\alpha^{(i,j)}$** — выход гиперсети (логиты) для ребра $(i,j)$ внутри клетки.  
  3. **Гиперсеть**: $\alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\mathbf S)$, где $\boldsymbol a$ — все обучаемые параметры гиперсети.  
- В вашем тексте «$\alpha: \Delta^{k-1}\times a\to \gamma$» стоит поправить: на самом деле гиперсеть выдает **логиты** $\alpha$, а не параметры $\gamma$. Более точно:  
  $$
    \alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\mathbf S), 
    \quad
    \alpha^{(i,j)}\in\mathbb R^{k}.
  $$
  Затем $\gamma^{(i,j)}$ получается из этих логитов по Softmax/Gumbel‐Softmax.  

---

### 2.4. Функция латентности и формулировка задачи

8. **Латентность архитектуры.**  
> В вашем тексте:  
> $$
> \mathrm{Latency}(\boldsymbol\gamma)
> = \sum_{(i,j)\in\mathcal E}\sum_{m=1}^{k}\gamma^{(m)}_{(i,j)}\,L^{(m)}.
> $$  

**Комментарий.**  
- Здесь нужно уточнить, что $L^{(m)}$ — это табличное значение «латентности» выбранной примитивной операции $m$ (например, conv3×3, conv5×5, и т. д.), измеренное на конкретном устройстве заранее (см. функцию `get_latency_table()` в коде).  
- В коде вы вычисляете `latency_loss` внутри `hyperloss` так:  
  ```python
  for edges, w_list in zip(cell.dag, weights):
      for mixed_op, weights in zip(edges, w_list):
          for op, w in zip(mixed_op._ops, weights):
              # op_name — строка с именем операции, например 'conv_3x3'
              latency_loss += w * lam[self.connect_dict[op_name]]
  ```
  Здесь `lam[self.connect_dict[op_name]]` — это именно одно из _компонент_ вектора сложности $\lambda$. То есть в реализации вы не используете заранее замеренные $L^{(m)}$, а просто отражаете в «латентности» – как **коэффициент** $\lambda$ вес операции. (Судя по коду, вы вовсе не подгружаете таблицу `L^{(m)}`, а *используете сам вектор сложности* как «латентность».)  
- Если же по идее вы хотели бы подключить реальную таблицу латентностей, нужно в коде заменять `lam[self.connect_dict[op_name]]` на `latency_table[op_name]`. Но в приведённом коде это не сделано. Вместо этого:  
  - `lam` изначально сэмплируется как вектор вероятностей (симплекс),  
  - Потом в `hyperloss` переменная `lam_` передается в `self.norm_lam(lam)`, а далее каждый элемент `lam_[j]` трактуется как «латентность этой операции».  

Из этого следует, что **ваша формулировка о суммировании $\gamma^{(m)} L^{(m)}$ не соответствует точной реализации**. В коде на самом деле  
$$

\text{Latency‐вклад} ;=;\sum\_{(i,j)} \sum\_{m=1}^k \gamma^{(m)}*{(i,j)};\underbrace{\lambda\_m}*{\text{компонента вектора сложности}}.

$$
То есть вы «контролируете 복αrchitecture complexity» не за счёт внешней таблицы $L^{(m)}$, а за счёт **самого вектора сложности** $\lambda$.  

**Если в тексте вы хотите остаться «в теории» и говорить, что $L^{(m)}$ — заранее измеренная латентность, нужно согласовать это с кодом (заменить `lam[...]` на таблицу). Если же код правильный и вы «латентность» берёте как $\lambda$-коэффициент, нужно переписать так:**
> «Мы трактуем сам вектор сложности $\lambda = ( \lambda_1,\dots,\lambda_k )$ как «стоимость» (pseudo‐latency) каждой примитивной операции. Тогда латентность архитектуры  
> $$
> \mathrm{Latency}(\boldsymbol\gamma;\,\lambda) \;=\; \sum_{(i,j)\in E}\sum_{m=1}^k \gamma_{(i,j)}^{(m)}\,\lambda_m.
> $$  
> Учёт этой латентности вносим в общий лосс помимо кросс‐энтропии.»

9. **Финальная задача.**  
Оригинал:  
$$

\min\_{\boldsymbol w,\boldsymbol a};
\mathbb E\_{\mathbf S\sim\mathcal U(\Delta^{k-1})}
;\mathbb E\_{\boldsymbol\gamma\sim\mathrm{GS}(H\_{\boldsymbol a}(\mathbf S),t)}
\Bigl\[,\mathcal L\_{\text{task}}(\boldsymbol w,\boldsymbol\gamma);
+;\kappa,\operatorname{Latency}(\boldsymbol\gamma)\Bigr].

$$

**Комментарий.**  
- В коде вы не используете два вложенных математических ожидания одновременно. У вас **в одном батче** вы сначала сэмплируете $\lambda\sim$Uniform‐симплекс, затем внутри `train_step` несколько раз (ровно `lam_sample_num` раз) пересэмплируете архитектуру (либо берёте детерминированный Softmax, либо Gumbel). Но финальный градиент по $\alpha$ считается через `hyperloss`, где семплирование $\gamma$ **не** происходит — там вы всегда берёте детерминированный Softmax.  
- Следует чётко указать, что оптимизация параметров $\boldsymbol a$ (гиперсети) происходит по «гипер‐лоссу», который равен кросс‐энтропии (на батче) плюс коэффициентная сумма «латентности‐взноса» (в коде это `latency_loss = \kappa \sum_{(i,j),m} w_{(i,j)}^{(m)} \,\lambda_m`). Градиент идет по $\boldsymbol a$ (через $\alpha=H_{\boldsymbol a}(\lambda)$).  
- Формально можно написать две задачи:  
  1. **Обучение весов сети** $\boldsymbol w$ (внутри всех операций `op.parameters()`), фиксируя гиперпараметры $\boldsymbol a$ и текущую $\lambda$.  
  2. **Обучение гиперсети** $\boldsymbol a$, где мы считаем «гипер‐потери» (hyper‐loss) на валидационном батче (в классическом DARTS), но в вашем коде вы, кажется, берёте train‐батч и сразу совместно обновляете.  

Исходя из кода, в `train_step` вы делаете:  
```python
self.w_optim.zero_grad()
self.alpha_optim.zero_grad()
loss_total = 0
for _ in range(self.lam_sample_num):
    lam = sample_lambda()  # Exponential+нормировка
    loss = self.hyperloss(trn_X, trn_y, lam)/lam_sample_num
    loss_total += loss
loss_total.backward()
self.w_optim.step()
self.alpha_optim.step()
```
То есть в **одном шаге** вы одновременно обновляете и $\boldsymbol w$, и $\boldsymbol a$ (то есть двигаетесь по градиенту лосса, который для $\boldsymbol a$ и $\boldsymbol w$ одинаков).  

В таком случае формулировка «одиночный уровень» справедлива, но нужно пояснить, что ожидание берётся только по $\lambda$ (внутри одной функции), а $\gamma$ каждый раз детерминированно вычисляется через Softmax (в функциональном режиме) или через GumbelSoftmax (если режим семплирования задан).  

Напряжённость в том, что в коде **не** используется отдельное валидационное множество для обновления $\alpha$ (как в классическом DARTS‐CC), а всё делается «на лету» на train‐ключах. Если вы переработали идею DARTS‐CC под одинуровневый спуск, это нужно явно отметить.  

---

## 3. Предлагаемый переработанный текст (Russian) с учётом замечаний

> **Замечание по структуре.** Я разбил текст на три основных части:  
> 1. Постановка задачи и введение клеток‐DAG.  
> 2. «Смешанная операция» и Gumbel‐Softmax.  
> 3. Гиперсеть и финальная функция потерь.  

Ниже приведён текст целиком. Изменения по сравнению с вашим оригиналом жёлтым шрифтом **выделены описательно**, но в окончательной форме можно не выделять.

---

### \section{Problem Statement}

#### 3.1 Постановка задачи

Ставится задача многоклассовой классификации на обучающем датасете  
$$

\mathfrak D = \bigl{(x\_i,y\_i)\bigr}\_{i=1}^{\mathcal N},
\quad x\_i \in \mathbf X,\quad y\_i \in \mathbf Y,

$$
где $\mathcal N$ — количество примеров, $\mathbf X$ — пространство входных данных (например, изображения), $\mathbf Y$ — множество меток (например, $\{1,\dots,C\}$ для $C$ классов).

В основе лежит идея дифференцируемого поиска архитектуры (DARTS) — нейросеть организуется в виде последовательности **клеток** (cells).  
Каждая клетка имеет одинаковый макет (topology), но **разные** параметры внутри. Формально **каждая клетка** — это ориентированный ациклический граф  
$$

\bigl(V,,E\bigr),\quad
V = {0,1,\dots,N},
\quad
E = {(i,j)\mid 0\le i\<j\le N}.

$$
Здесь метки вершин:  
- $i=0$ и $i=1$ — «фиксированные» входы (результаты двух предыдущих слоёв),  
- $i=2,\dots,N$ — $N-1$ внутренних промежуточных узлов.  
На каждом ребре $(i,j)\in E$ выбирается некоторая операция (primitive) из множества  
$$

\mathcal O = {\mathbf{o}^{(1)},\mathbf{o}^{(2)},\dots,\mathbf{o}^{(k)}},

$$
где $k = |\mathcal O|$ — число примитивов (например, свёртки $3\times3$, $5\times5$, $3\times3$ dilated, max‐pool, avg‐pool, skip‐connect, «none» и т. д.).  

Если мы обозначим через $\mathbf{g}^{(i,j)}$ «смешанную» (mixed) операцию на ребре $(i,j)$, то для каждой внутренней вершины $j$ выход
$$

\boldsymbol{x}^{(j)}
\= \sum\_{(i,j)\in E} \mathbf{g}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr).

$$
В обычном DARTS $\mathbf{g}^{(i,j)}$ выглядит как  
$$

\mathbf{g}^{(i,j)}(x)
\= \sum\_{m=1}^k
\underbrace{\alpha^{(i,j)}*m}*{\text{вес (логит) \$m\$-й операции}}
;\mathbf{o}^{(m)}(x),

$$
где $\alpha^{(i,j)}\in\mathbb R^k$ — обучаемый вектор логитов, и затем применяется Softmax (или Gumbel‐Softmax) по этим логитам, чтобы получить «веса» $\gamma^{(i,j)}\in\Delta^{k-1}$.  

**Цель**: найти для каждого ребра $(i,j)$ и для каждой клетки ту операцию, которая в итоге даст минимальную ошибку классификации на тестовых данных.

#### 3.2 Дифференцируемое семплирование (Gumbel‐Softmax)

Чтобы свести дискретную задачу выбора операции к дифференцируемой, используется техника «смешанной» операции (mixed op) с Gumbel‐Softmax \cite{Jang2017}.  

1. **«Сырые» логиты**. Для каждого ребра $(i,j)$ у нас есть вектор $\alpha^{(i,j)}\in\mathbb R^k$.  
2. **Плавный режим.** Детerministic Softmax (без шума):  
$$

\gamma^{(i,j)}
\= \mathrm{Softmax}\bigl(\alpha^{(i,j)}/t\bigr),
\quad
\gamma^{(i,j)}\in\Delta^{k-1},

$$
где $t>0$ — *температура*. При $t\to0$ Softmax переходит к «жёсткому» выбору (горячее кодирование), при больших $t$ веса «размыты».  
3. **Случайное семплирование.** Gumbel‐Softmax (технически RelaxedOneHotCategorical) позволяет получать «псевдо‐горячие» вектора, приближённые к одному‐горячему, но всё ещё дифференцируемые:  
$$

\gamma^{(i,j)}
\sim \mathrm{GumbelSoftmax}\bigl(\alpha^{(i,j)},,t\bigr).

$$

После получения $\gamma^{(i,j)}=(\gamma^{(i,j)}_1,\dots,\gamma^{(i,j)}_k)$ «смешанная» операция вычисляется так:  
$$

\widehat{\mathbf{g}}^{(i,j)}(x)
\= \sum\_{m=1}^k \gamma^{(i,j)}\_m,\mathbf{o}^{(m)}(x).

$$

**Замечание, соответствие коду:**  
- В файле `SearchCNNControllerWithHyperNet.forward` при `sampling_mode='softmax'` вы берёте  
  ```python
  weights_normal = [F.softmax(alpha(lam)/t, dim=-1) for alpha in self.hyper_normal]
  ```
  То есть детерминированно получаете $\gamma$.  
- При `sampling_mode='gumbel-softmax'` вы вызываете  
  ```python
  torch.distributions.RelaxedOneHotCategorical(self.t, logits=alpha(lam)).rsample([batch_size])
  ```
  что семплирует $\gamma$ размером `[batch_size, k]`.  
- При `sampling_mode='naive'` вы вообще берёте вектор логитов без Softmax (`gamma = alpha`), но затем в `MixedOp` умножаете эти логиты на операции (это скорее «экспериментальный» режим без нормировки).  

Однако! **В функции гипер‐потерь (`hyperloss`) вы всегда используете детерминированный Softmax** вне зависимости от `sampling_mode`. Это нужно подчеркнуть в тексте.

#### 3.3 Гиперсеть для контроля сложности

Вместо того чтобы непосредственно хранить и обновлять «сырые» логиты $\alpha^{(i,j)}$ для каждого ребра, мы вводим **гиперсеть** $H_{\boldsymbol a}$, параметризованную $\boldsymbol a$, которая на вход получает **вектор сложности** $\lambda \in \Delta^{k-1}$ и выдаёт сразу все нужные логиты $\alpha^{(i,j)}$. 

- **Вектор сложности**  
$$

\lambda = (\lambda\_1,\dots,\lambda\_k)\in\Delta^{k-1},
\quad
\sum\_{m=1}^k \lambda\_m = 1,;\lambda\_m\ge 0.

$$
Он **сэмплируется** в начале каждой мини‐партии (mini‐batch) из равномерного распределения по симплексу. В коде это реализовано как
```python
k = torch.distributions.Exponential(1.0).sample([SIMPLEX_D]).to(device)
lam = k / sum(k)
```
где `SIMPLEX_D = k` (число примитивов).  

- **Гиперсеть**  
Обозначим через $\alpha_{\boldsymbol a}^{(i,j)}(\lambda)$ логиты, сгенерированные гиперсетью для ребра $(i,j)$ в зависимости от $\lambda$. Формально:
$$

```
\alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\lambda),
\quad 
\alpha^{(i,j)}\in\mathbb R^k.
```

$$$
В коде у каждого узла (node) каждой клетки есть свой экземпляр класса `HyperNet`, который внутри хранит несколько линейных слоёв. Собранные параметры всех `HyperNet`-экземпляров объединены в список `self.hyper_normal` и `self.hyper_reduce`.  
Технически в коде:  
```python
for i in range(n_nodes):
    # для каждой нормальной клетки (нередьюс) и клетки‐редьюс создаём HyperNet
    hypernet = HyperNet(...)
    self.hyper_normal.append(hypernet)
    self.alpha_normal.extend(list(hypernet.parameters()))
    # и аналогично для редьюс-клеток
    hypernet = HyperNet(...)
    self.hyper_reduce.append(hypernet)
    self.alpha_reduce.extend(list(hypernet.parameters()))
```
Поэтому для каждого узла есть свой `alpha(lam)`.

- **Получение «весов операций»**  
После того как гиперсеть выдала $\alpha^{(i,j)}(\lambda)$, мы получаем «веса» $\gamma^{(i,j)}$ двумя способами:
1. **Во время прямого прохода** (метод `forward` в контроллере) в зависимости от `sampling_mode`:
   - Softmax: $\gamma = \mathrm{Softmax}(\alpha/t)$.
   - Gumbel‐Softmax: $\gamma \sim \mathrm{GumbelSoftmax}(\alpha,\,t)$.
   - Naive: $\gamma = \alpha$ (без нормировки).  
2. **При вычислении «гипер‐лоссов» (hyperloss)**:  
   ```python
   weights = [alpha(lam) for alpha in self.hyper_normal]
   weights = [F.softmax(w, dim=-1) for w in weights]
   ```
   Здесь **всегда** используется просто Softmax без шума. Именно поэтому, хотя вы пишете «$\gamma\sim GS(\alpha,t)$», внутри гипер‐лоссов фактически  
   $$
   \gamma^{(i,j)} = \mathrm{Softmax}\bigl(\alpha^{(i,j)}(\lambda)\bigr).
   $$
   Если вы хотите точнее описать реализацию, то нужно привести разделение «во время train_step» и «во время вычисления hyperloss» (см. ниже).

#### 3.4 Оптимизационная задача с учётом «латентности» (веса сложности)

**Введение «латентности»:**  
В оригинальном DARTS-CC каждая примитивная операция $m$ имеет заранее измеренное время (латентность) $L^{(m)}$, и суммарная латентность архитектуры определяется как  
$$$

\mathrm{Latency}(\gamma)
\= \sum\_{(i,j)\in E}\sum\_{m=1}^k \gamma\_{(i,j)}^{(m)},L^{(m)}.

$$
Затем в лосс добавляется слагаемое $\kappa\cdot\mathrm{Latency}(\gamma)$, чтобы получить компромисс «точность—скорость».  

Однако в вашем коде вместо заранее измеренной $L^{(m)}$ **сам вектор сложности** $\lambda = (\lambda_1,\dots,\lambda_k)$ используется как «стоимость» (pseudo‐latency) каждого примитива:  
$$

\mathrm{Latency}\bigl(\gamma;,\lambda\bigr)
;=;
\sum\_{(i,j)\in E} \sum\_{m=1}^k \gamma\_{(i,j)}^{(m)},\lambda\_m.

$$
Именно эта сумма (`latency_loss`) входит в функцию `hyperloss`.  

> **Важно:** если вы планировали действительно подсоединить таблицу $L^{(m)}$ из `get_latency_table()`, то в коде нужно заменить `lam[self.connect_dict[op_name]]` на `latency_table[op_name]`. В текущей реализации же «$\lambda$» и «$L$» ис­пользуются одинаково.  

**Формулировка полной задачи:**  
Мы хотим совместно оптимизировать:  
- Параметры сети (веса всех операций) $\boldsymbol w$,  
- Параметры гиперсети (логиты $\boldsymbol a$).  

Каждый мини‐батч мы:  
1. Сэмплируем $\lambda\sim U(\Delta^{k-1})$ (или через Exponential+нормализацию).  
2. Получаем от гиперсети логиты $\alpha^{(i,j)}(\lambda)$ для всех $(i,j)\in E$.  
3. Получаем «веса» $\gamma^{(i,j)}$ (через Softmax или Gumbel‐Softmax, в зависимости от режима).  
4. Вычисляем прямой проход сети и кросс‐энтропию $\mathcal L_\mathrm{task}(\boldsymbol w,\boldsymbol\gamma)$.  
5. Вычисляем «латентность»  
$$

\mathrm{Latency}(\boldsymbol\gamma;\lambda)
\= \sum\_{(i,j)\in E} \sum\_{m=1}^k \gamma\_{(i,j)}^{(m)},\lambda\_m.

$$
6. Составляем лосс  
$$

\mathcal L\_{\text{full}}
\= \mathcal L\_\mathrm{task}(\boldsymbol w,\boldsymbol\gamma)
;+; \kappa ,\mathrm{Latency}(\boldsymbol\gamma;\lambda).

$$

Далее производим шаг градиентного спуска по $\boldsymbol w$ и по $\boldsymbol a$ (он влияет на $\gamma$ через $\alpha = H_{\boldsymbol a}(\lambda)$).  

Если описать это формально (без дробления на два уровня), то можно написать:  
$$

\min\_{\boldsymbol w,;\boldsymbol a}
\mathbb E\_{\lambda\sim U(\Delta^{k-1})};
\bigl\[
\underbrace{\mathcal L\_\mathrm{task}\bigl(\boldsymbol w,\gamma(\lambda;,\boldsymbol a)\bigr)}\_{\text{кросс‐энтропия}}

* \kappa; \underbrace{\mathrm{Latency}\bigl(\gamma(\lambda;,\boldsymbol a),,\lambda\bigr)}\_{\text{вес сложности}}\bigr],

$$$
где $\gamma(\lambda;\,\boldsymbol a)$ определяется через  
1. $\alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\lambda)$,  
2. $\gamma^{(i,j)} = \mathrm{Softmax}(\alpha^{(i,j)}/t)$ (или Gumbel, если семплируется архитектура для «inference»).

В коде вы при тренировке используете именно такой «одностадийный» градиентный спуск (без отдельной валидации для $\boldsymbol a$).

---

## 4. Проверка «что в коде»: $\gamma$ без GS или с GS?

- **В `forward` (во время прямого прохода)**:  
  - Если `sampling_mode='softmax'`, берётся $\gamma = \mathrm{Softmax}(\alpha/t)$.  
  - Если `sampling_mode='gumbel-softmax'`, берётся $\gamma\sim\mathrm{GumbelSoftmax}(\alpha,t)$.  
  - Если `sampling_mode='naive'`, просто $\gamma = \alpha$ (никаких нормализующих операций).  

- **В `hyperloss` (во время подсчёта лосса для обновления $\alpha$ и $\lambda$)**:  
  ```python
  weights = [alpha(lam) for alpha in self.hyper_reduce]
  weights = [F.softmax(w, dim=-1) for w in weights]
  ```
  Здесь всегда используется **чистый Softmax**, даже если `sampling_mode='gumbel-softmax'`.  

Поэтому в вашем тексте нужно **прописать отдельно**, что при обучении гиперсети (обновлении $\boldsymbol a$) применяется детерминированный Softmax (`\gamma = \mathrm{Softmax}(\alpha)`), а при семплировании архитектуры (для прямого прохода/финальной оценки) может использоваться Gumbel‐Softmax.

---

## 5. Комментарии по переходам между блоками логики

1. **От общей постановки к «смешанной» операции.**  
   - В тексте можно добавить короткое пояснение:  
     > «В классическом DARTS мы для каждого ребра $(i,j)$ напрямую обучаем логиты $\alpha^{(i,j)}\in\mathbb R^k$ и получаем «плавное» представление смешанной операции  
     > $$
     >   \mathbf{g}^{(i,j)}(x) 
     >   = \sum_{m=1}^k \gamma^{(i,j)}_m\, \mathbf{o}_m(x),
     >   \quad
     >   \gamma^{(i,j)} = \mathrm{Softmax}\bigl(\alpha^{(i,j)}/t\bigr).
     > $$
     >  
     > Однако в нашем методе мы не храним отдельно $\alpha^{(i,j)}$, а вместо них используем гиперсеть, которая генерирует сразу все $\alpha^{(i,j)}$ в зависимости от **вектора сложности** $\lambda$.»  

2. **От «смешанной» операции к гиперсети.**  
   - После описания Gumbel‐Softmax (или Softmax) стоит написать:  
     > «Таким образом нам требуется хранить и обновлять большое количество векторов логитов $\{\alpha^{(i,j)}\;\vert\;(i,j)\in E\}$. Чтобы управлять «комплексностью» поиска, вместо прямого обучения каждого $\alpha^{(i,j)}$ вводим гиперсеть. Гиперсеть $H_{\boldsymbol a}$ на вход принимает **вектор сложности** $\lambda$, и сразу выдаёт все $\alpha^{(i,j)}$. Поскольку $\lambda$ мы можем регулировать, мы тем самым контролируем сложность выбираемых операций во всей сети одним глобальным параметром.»  

3. **От гиперсети к формулировке задачи.**  
   - После введения гиперсети нужно пояснить:  
     > «Пусть $\alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\lambda)$. Далее получаем «веса»  
     > $$
     > \gamma^{(i,j)} 
     > = 
     > \begin{cases}
     >   \mathrm{Softmax}\bigl(\alpha^{(i,j)}/t\bigr), 
     >     &\text{в режиме детерминированного спуска;}\\
     >   \mathrm{GumbelSoftmax}\bigl(\alpha^{(i,j)},\,t\bigr), 
     >     &\text{при нужде семплировать архитектуру.}
     > \end{cases}
     > $$
     >  
     > Архитектурный выход клетки на вершине $j$:
     > $$
     > \boldsymbol{x}^{(j)} 
     > = \sum_{(i,j)\in E} \sum_{m=1}^k \gamma^{(i,j)}_m\,\mathbf{o}^{(m)}\bigl(\boldsymbol{x}^{(i)}\bigr).
     > $$  
     >  
     > Далее, чтобы контролировать «латентность» (сложность) сети, мы трактуем вектор $\lambda$ как «стоимость» каждой примитивной операции. Тогда  
     > $$
     > \mathrm{Latency}(\gamma;\,\lambda) 
     > = \sum_{(i,j)\in E}\sum_{m=1}^k \gamma_{(i,j)}^{(m)}\,\lambda_m.
     > $$  
     >  
     > Общий лосс, который мы минимизируем, становится  
     > $$
     > \mathcal L_\mathrm{full} = \mathcal L_\mathrm{task}\bigl(\boldsymbol w,\gamma(\lambda)\bigr)
     > + \kappa\,\mathrm{Latency}\bigl(\gamma(\lambda);\lambda\bigr),
     > $$
     > где $\mathcal L_\mathrm{task}$ — это кросс‐энтропия по истинным меткам. Наша цель — найти оптимальные $\boldsymbol w$ и $\boldsymbol a$ так, чтобы *в среднем* по $\lambda$ этот лосс минимизировался:  
     > $$
     > \min_{\boldsymbol w,\boldsymbol a}
     > \mathbb E_{\lambda\sim U(\Delta^{k-1})}
     > \bigl[
     >   \mathcal L_\mathrm{task}\bigl(\boldsymbol w,\gamma(\lambda)\bigr)
     >   + \kappa\,\mathrm{Latency}\bigl(\gamma(\lambda);\lambda\bigr)
     > \bigr].
     > $$»

Таким образом вы получаете полное и непротиворечивое изложение, которое строго соответствует коду:

1. **Вектор сложности** $\lambda \in \Delta^{k-1}$ сэмплируется внутри `train_step`.
2. **Гиперсеть** $H_{\boldsymbol a}$ генерирует логиты $\alpha^{(i,j)}$.
3. **Вычисление «весов»** $\gamma^{(i,j)}$  
   - при подсчёте градиента (hyperloss) — детерминантный Softmax,  
   - при прямом проходе (forward) — опционально Gumbel‐Softmax (в зависимости от `sampling_mode`).  
4. **Формирование лосса**: кросс‐энтропия + $\kappa\cdot$«латентность» (зависящая от $\lambda$ и $\gamma$).

---

## 6. Подведение итогов: что нужно поправить в вашем тексте

1. **Явно определить все переменные**:
   - $\lambda$ (или $\mathbf S$) — вектор сложности, ясно связь с кодом (`lam`).
   - $\alpha^{(i,j)}$ — логиты от гиперсети.
   - $\gamma^{(i,j)}$ — «веса» операций, получаемые через Softmax/GumbelSoftmax.
   - $N$ — число узлов внутри клетки (обычно 4).  
   - $k = |\mathcal O|$ — число примитивов (соответствует размерности $\lambda$).  
2. **Уточнить «вектор сложности → гиперсеть → $\alpha$ → $\gamma$ → смешанная операция → выход клеток».**  
3. **Расписать, что в `hyperloss` используется детерминированный Softmax**, а **при семплировании** (в `forward`) — Gumbel‐Softmax (если это задано).  
4. **Изменить определение «Latency»** так, чтобы оно соответствовало коду:  
   - Либо писать «$L^{(m)}$ — это заранее измеренная латентность», и в коде реально брать $L^{(m)}$ из таблицы (но в коде не так);  
   - Либо, как в текущем коде, «мы используем $\lambda_m$ как «стоимость операции» без привлечения внешней таблицы».  
5. **Добавить логические переходы** между секциями (см. пункт 5 выше).  
6. **Сократить дублирование** формул (например, не писать дважды про Softmax и Gumbel‐Softmax без перехода).

---

## 7. Полный исправленный текст (конечный вариант)

Ниже приводится окончательная версия «Problem Statement» **на русском** с учётом всех правок и комментариев. Если какие‐то фрагменты покажутся избыточными или вам захочется добавить дополнительные ссылки на код, можно это легко «пристроить» в скобках.

> \section{Problem Statement}
>
> \subsection{Постановка задачи}
> Задача многоклассовой классификации формулируется как поиск функции $f:\mathbf X\to\mathbf Y$ на обучающем наборе
> $$
> \mathfrak D = \bigl\{(x_i,y_i)\bigr\}_{i=1}^{\mathcal N}, 
> \quad x_i\in\mathbf X,\;y_i\in\mathbf Y,\;\mathcal N=\bigl|\mathfrak D\bigr|.
> $$
> В основе лежит идея дифференцируемого архитектурного поиска (DARTS). Нейросеть состоит из $L$ слоёв (этапов), каждый из которых реализован как **клетка**. Клетка — это ориентированный ациклический граф
> $$
> \bigl(V,\,E\bigr),\qquad
> V = \{0,1,\dots,N\}, 
> \quad
> E = \bigl\{(i,j)\mid 0\le i<j\le N\bigr\}.
> $$
> Здесь вершины $0$ и $1$ — «фиктивные» входы (результаты двух предыдущих слоёв), а $2,\dots,N$ — $N-1$ внутренних узлов. На каждом ребре $(i,j)\in E$ выбирается одна из примитивных операций
> $$
> \mathcal O = \bigl\{\mathbf{o}^{(1)},\mathbf{o}^{(2)},\dots,\mathbf{o}^{(k)}\bigr\},
> $$
> где $k=|\mathcal O|$ — число рассмотренных примитивов (например, conv3×3, conv5×5, dil‐conv3×3, max‐pooling, avg‐pooling, skip‐connect, zero и т. д.).
>
> Пусть $\boldsymbol{x}^{(i)}$ — вектор признаков в вершине $i$. Тогда выход вершины $j$ вычисляется как сумма по всем входящим рёбрам:
> $$
> \boldsymbol{x}^{(j)}
> = \sum_{(i,j)\in E} 
> \underbrace{\mathbf{g}^{(i,j)}\bigl(\boldsymbol{x}^{(i)}\bigr)}_{\text{«cмешанная» операция на ребре $(i,j)$}}.
> $$
>  
> В классическом DARTS «смешанная» операция на ребре $(i,j)$ строится так:
> $$
> \mathbf{g}^{(i,j)}(x) 
> = \sum_{m=1}^k \gamma_{(i,j),\,m}\,\mathbf{o}^{(m)}(x),
> \quad 
> \gamma_{(i,j)} = \mathrm{Softmax}\bigl(\alpha^{(i,j)}/t\bigr),
> $$
> где $\alpha^{(i,j)}\in\mathbb R^k$ — обучаемый вектор логитов для ребра $(i,j)$, $t>0$ — температура,  
> $$
> \mathrm{Softmax}\bigl(\alpha/t\bigr)_m 
> = \frac{\exp(\alpha_m/t)}{\sum_{n=1}^k\exp(\alpha_n/t)}, 
> \quad \gamma_{(i,j)} \in \Delta^{\,k-1}.
> $$
> Для получения «твердого» семпла (one‐hot) иногда используют Gumbel‐Softmax:
> $$
> \gamma_{(i,j)} \sim \mathrm{GumbelSoftmax}\bigl(\alpha^{(i,j)},\,t\bigr).
> $$
>  
> **Цель**: для каждого ребра $(i,j)$ определить такую операцию из $\mathcal O$, при которой итоговая ошибка классификации минимальна.
>
> \subsection{Дифференцируемое семплирование (Softmax и Gumbel‐Softmax)}  
> Чтобы свести выбор из дискретного множества $\mathcal O$ к дифференцируемой задаче, мы используем технику «смешанных» операций \cite{Jang2017}.  
> 1. Для каждого ребра $(i,j)$ хранится вектор логитов $\alpha^{(i,j)}\in\mathbb R^k$.  
> 2. В детерминированном режиме (режим «softmax») получаем веса  
>    $$
>    \gamma^{(i,j)} 
>    = \mathrm{Softmax}\bigl(\alpha^{(i,j)}/t\bigr), \quad t>0.
>    $$
>    Чем меньше $t$, тем «жестче» (ближе к one‐hot) распределение.  
> 3. В стохастическом режиме (режим «gumbel‐softmax») семплируем  
>    $$
>    \gamma^{(i,j)} 
>    \sim \mathrm{GumbelSoftmax}\bigl(\alpha^{(i,j)},\,t\bigr), 
>    $$
>    что делает архитектуру стохастической, но всё ещё дифференцируемой.  
>  
> После этого «смешанная» операция $\mathbf{g}^{(i,j)}$ вычисляется как  
> $$
> \widehat{\mathbf{g}}^{(i,j)}(x) 
> = \sum_{m=1}^k \gamma^{(i,j)}_m\,\mathbf{o}^{(m)}(x).
> $$  
>  
> **Соответствие коду** (`SearchCNNControllerWithHyperNet.forward`):  
> ```python
> if sampling_mode == 'softmax':
>     weights_normal = [F.softmax(alpha(lam)/t, dim=-1) for alpha in self.hyper_normal]
>     weights_reduce = [F.softmax(alpha(lam)/t, dim=-1) for alpha in self.hyper_reduce]
> elif sampling_mode == 'gumbel-softmax':
>     weights_normal = [torch.distributions.RelaxedOneHotCategorical(self.t, logits=alpha(lam)).rsample([batch_size]) 
>                       for alpha in self.hyper_normal]
>     weights_reduce = [torch.distributions.RelaxedOneHotCategorical(self.t, logits=alpha(lam)).rsample([batch_size]) 
>                       for alpha in self.hyper_reduce]
> elif sampling_mode == 'naive':
>     weights_normal = [alpha(lam) for alpha in self.hyper_normal]
>     weights_reduce = [alpha(lam) for alpha in self.hyper_reduce]
> else:
>     raise ValueError('Bad sampling mode')
> ```
> То есть при прямом проходе мы можем выбирать либо детерминированный «плавный» режим, либо Gumbel‐Softmax.  
>  
> **Важно:** При вычислении «гипер‐лосса» (`hyperloss`) мы, независимо от `sampling_mode`, **всегда** используем детерминированный Softmax:  
> ```python
> weights = [alpha(lam) for alpha in self.hyper_normal]
> weights = [F.softmax(w, dim=-1) for w in weights]
> ```
> Это означает, что стохастическое семплирование Gumbel‐Softmax используется только при «forward» (inference или при обучении архитектуры), а для градиентного обновления $\boldsymbol a$ мы считаем плотные «плавные» веса через Softmax без Gumbel‐шума.

> \subsection{Гиперсеть для контроля сложности}  
> Вместо того чтобы хранить отдельные $\alpha^{(i,j)}$ для каждого ребра, мы вводим **гиперсеть** $H_{\boldsymbol a}$, параметризованную параметрами $\boldsymbol a$, которая на вход получает **вектор сложности**  
> $$
> \lambda = (\lambda_1,\dots,\lambda_k)\in\Delta^{k-1}, 
> \quad \sum_{m=1}^k\lambda_m=1,\;\lambda_m\ge0,
> $$
> а на выходе выдаёт сразу все векторы логитов $\{\alpha^{(i,j)}\}_{(i,j)\in E}$.  
> - **Сэмплирование $\lambda$.** В каждой mini‐batch мы генерируем $\lambda$ следующим образом:  
>   ```python
>   k = torch.distributions.Exponential(1.0).sample([SIMPLEX_D]).to(device)
>   lam = k / sum(k)
>   ```
>   где `SIMPLEX_D = k = |\mathcal O|` — число примитивов. Это эквивалентно взятию $\lambda$ из равномерного распределения на симплексе $\Delta^{k-1}$.  
> - **Генерация логитов.** Для каждого узла (node) внутри каждой клетки есть свой `HyperNet`, который на входе получает $\lambda$ и возвращает логиты $\alpha(\lambda)\in\mathbb R^k$.  
>   ```python
>   alpha^{(i,j)} = H_{\boldsymbol a}^{(i,j)}(\lambda).
>   ```
>   Все параметры всех экземпляров `HyperNet` (их веса и смещения) объединены в общий вектор $\boldsymbol a$.  
>   
> Далее, узнав $\alpha^{(i,j)}$, получаем «веса» $\gamma^{(i,j)}$ (Softmax или Gumbel‐Softmax) и строим «смешанную» операцию.  

> \subsection{Оптимизационная задача с учётом «латентности»}
> Каждому примитиву $\mathbf{o}^{(m)}$ мы приписываем «стоимость» (псевдо­латентность) $\lambda_m$, взятую из того же вектора $\lambda$. Тогда «латентность» всей архитектуры определяется как  
> $$
> \mathrm{Latency}\bigl(\gamma;\,\lambda\bigr)
> = \sum_{(i,j)\in E}\sum_{m=1}^k \gamma^{(i,j)}_m\,\lambda_m.
> $$
> Соответствующее слагаемое в лоссе служит штрафом за «сложность» выбранных операций.  
> 
> Обозначим через $\mathcal L_\mathrm{task}(\boldsymbol w,\gamma)$ – кросс‐энтропию (или иное стандартное измерение качества) сети с весами $\boldsymbol w$, при фиксированных «весах» операций $\gamma$.  
> Тогда для заданного $\lambda$ и соответствующей ему архитектуры $\gamma(\lambda;\,\boldsymbol a)$ общий лосс:
> $$
> \mathcal L_{\mathrm{full}}\bigl(\boldsymbol w,\lambda;\,\boldsymbol a\bigr)
> = \mathcal L_\mathrm{task}\bigl(\boldsymbol w,\,\gamma(\lambda;\boldsymbol a)\bigr)
> \;+\;
> \kappa\,\mathrm{Latency}\bigl(\gamma(\lambda;\boldsymbol a);\lambda\bigr),
> $$
> где $\kappa>0$ — коэффициент, регулирующий компромисс «точность—сложность».  
> 
> **Наша цель** — минимизировать математическое ожидание этого лосса по $\lambda$ и по стохастическому семплу $\gamma$:
> $$
> \min_{\boldsymbol w,\boldsymbol a}
> \mathbb E_{\lambda\sim U(\Delta^{k-1})}
> \Bigl[
>   \underbrace{\mathcal L_\mathrm{task}\bigl(\boldsymbol w,\gamma(\lambda)\bigr)}_{\text{кросс‐энтропия}} 
>   \;+\;
>   \kappa\,\underbrace{\mathrm{Latency}\bigl(\gamma(\lambda);\lambda\bigr)}_{\text{штраф за сложность}}
> \Bigr].
> $$
> Здесь  
> - $\gamma(\lambda)$ может быть либо детерминированным Softmax (при обучении гиперсети в `hyperloss`), либо семплированным Gumbel‐Softmax (в `forward`, когда мы хотим «попробовать» стохастическую архитектуру).  
> - Градиент по $\boldsymbol w$ и по $\boldsymbol a$ рассчитывается в одном шаге градиентного спуска (в коде — метод `train_step`).  
> 
> **Замечание по реализации (`train_step`):**  
> ```python
> self.w_optim.zero_grad()
> self.alpha_optim.zero_grad()
> loss_total = 0
> for _ in range(self.lam_sample_num):
>     lam = sample(lambda)         # sample lambda из симплекса
>     loss = self.hyperloss(X, y, lam) / self.lam_sample_num
>     loss_total += loss
> loss_total.backward()
> self.w_optim.step()
> self.alpha_optim.step()
> ```  
> То есть одновременно обновляются и $\boldsymbol w$, и $\boldsymbol a$, и каждую итерацию мы усредняем по нескольким (``lam_sample_num``) семплам $\lambda$. Внутри `hyperloss` веса операций вычисляются как чистый Softmax(без Gumbel‐шума), и далее суммируется «latency_loss = κ⋅∑_{(i,j),m} γ_{(i,j)}^{(m)} λ_m».  

**Итог**: получаем чёткую постановку задачи, которая реализована в коде. Ниже перечислю ключевые моменты, на которые нужно обратить внимание при проверке соответствия:

1. **Определить** явные множества и переменные:
   - $\mathfrak D,\,\mathbf X,\,\mathbf Y,\;\mathcal N$.  
   - Граф клеток: $V = \{0,1,\dots,N\},\,E=\{(i,j)\mid i<j\}$.  
   - Множество примитивов $\mathcal O$ размером $k$.  
   - Вектор сложности $\lambda\in\Delta^{k-1}$.  
   - Гиперсеть $H_{\boldsymbol a}$, выдающая логиты $\alpha^{(i,j)}(\lambda)\in\mathbb R^k$.  
   - «Веса операций» $\gamma^{(i,j)}$ = Softmax или Gumbel‐Softmax от $\alpha^{(i,j)}$.  

2. **Ясно разграничить** два режима:
   - В `forward`: можно использовать Gumbel‐Softmax для стохастического семплирования $\gamma$.  
   - В `hyperloss`: всегда применяется детерминированный Softmax для вычисления градиента по $\boldsymbol a$.  

3. **Указать** используемую «латентность» — в коде это именно компоненты $\lambda$, а не внешняя таблица. Если вы хотите, чтобы «$L^{(m)}$» реально хранилась в таблице, надо привести соответствующие правки в код.  

4. **Добавить плавные переходы** между разделами:  
   - Почему сначала классический DARTS смешивает операции?  
   - Почему нам не нравится хранить множество $\alpha^{(i,j)}$ отдельно, и мы вводим гиперсеть?  
   - Как гиперсеть позволяет контролировать сложность одной «ручкой» – вектором $\lambda$.  
   - Как всё это встраивается в единый градиентный спуск.  

После этих правок ваш текст станет полностью согласован с тем, что реально происходит в коде, и при этом сохранит почти все ваши исходные формулировки, исправив лишь точечные неточности и добавив недостающие пояснения.
$$$
